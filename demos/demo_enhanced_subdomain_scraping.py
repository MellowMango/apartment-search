#!/usr/bin/env python3
"""
Enhanced Subdomain Scraping Demo for Lynnapse

This demo showcases the enhanced capabilities for handling universities
with complex subdomain-based structures like Carnegie Mellon University.

Features demonstrated:
- Enhanced sitemap discovery across multiple subdomains
- Department-specific subdomain enumeration  
- Intelligent pattern recognition for diverse university structures
- Robust fallback mechanisms for difficult sites
"""

import asyncio
import json
import logging
from typing import Dict, Any

from lynnapse.core.university_adapter import UniversityAdapter
from lynnapse.core.adaptive_faculty_crawler import AdaptiveFacultyCrawler

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def demo_enhanced_subdomain_discovery():
    """Demonstrate enhanced subdomain discovery capabilities."""
    
    print("ğŸ”¬ Lynnapse Enhanced Subdomain Discovery Demo")
    print("=" * 60)
    
    # Test universities with different subdomain structures
    test_universities = [
        {
            "name": "Carnegie Mellon University",
            "description": "Complex subdomain-based structure (psychology.cmu.edu, cs.cmu.edu, etc.)",
            "target_department": "psychology"
        },
        {
            "name": "Stanford University", 
            "description": "Mixed structure with some department subdomains",
            "target_department": "psychology"
        },
        {
            "name": "University of California, Berkeley",
            "description": "Traditional structure for comparison",
            "target_department": "psychology"
        }
    ]
    
    adapter = UniversityAdapter()
    
    for university in test_universities:
        print(f"\nğŸ›ï¸  Testing: {university['name']}")
        print(f"ğŸ“ Structure: {university['description']}")
        print("-" * 50)
        
        try:
            # Discover university structure
            print("ğŸ” Discovering university structure...")
            pattern = await adapter.discover_university_structure(
                university["name"]
            )
            
            print(f"âœ… Discovery successful!")
            print(f"   ğŸ”— Base URL: {pattern.base_url}")
            print(f"   ğŸ“Š Confidence: {pattern.confidence_score:.2f}")
            print(f"   ğŸŒ Faculty patterns found: {len(pattern.faculty_directory_patterns)}")
            
            # Show subdomain information if available
            if pattern.department_subdomains:
                print(f"   ğŸ¢ Department subdomains found: {len(pattern.department_subdomains)}")
                for dept_name, subdomain_url in pattern.department_subdomains.items():
                    print(f"      â€¢ {dept_name}: {subdomain_url}")
            
            if pattern.subdomain_patterns:
                print(f"   ğŸ”— Subdomain patterns: {len(pattern.subdomain_patterns)}")
                for subdomain in pattern.subdomain_patterns[:3]:  # Show first 3
                    print(f"      â€¢ {subdomain}")
            
            # Discover departments
            print("\nğŸ¢ Discovering departments...")
            departments = await adapter.discover_departments(
                pattern, 
                target_department=university.get("target_department")
            )
            
            if departments:
                print(f"âœ… Found {len(departments)} departments:")
                for dept in departments:
                    subdomain_info = " (SUBDOMAIN)" if dept.is_subdomain else ""
                    print(f"   ğŸ“š {dept.name}{subdomain_info}")
                    print(f"      ğŸ”— URL: {dept.url}")
                    print(f"      ğŸ“Š Confidence: {dept.confidence:.2f}")
                    print(f"      ğŸ—ï¸  Structure: {dept.structure_type}")
                    if dept.faculty_count_estimate > 0:
                        print(f"      ğŸ‘¥ Est. Faculty: {dept.faculty_count_estimate}")
            else:
                print("âŒ No departments found")
                
        except Exception as e:
            print(f"âŒ Error: {e}")
            logger.error(f"Failed to process {university['name']}: {e}")
    
    await adapter.close()


async def demo_enhanced_faculty_scraping():
    """Demonstrate end-to-end faculty scraping with subdomain support."""
    
    print("\n" + "=" * 60)
    print("ğŸ“ Enhanced Faculty Scraping Demo")
    print("=" * 60)
    
    # Test with Carnegie Mellon University Psychology Department
    print("\nğŸ§  Testing Carnegie Mellon University Psychology Department")
    print("ğŸ¯ This should use subdomain-based discovery (psychology.cmu.edu)")
    print("-" * 50)
    
    crawler = AdaptiveFacultyCrawler(enable_lab_discovery=True)
    
    try:
        result = await crawler.scrape_university_faculty(
            university_name="Carnegie Mellon University",
            department_filter="psychology",
            max_faculty=5  # Limit for demo
        )
        
        if result["success"]:
            print(f"âœ… Scraping successful!")
            print(f"   ğŸ›ï¸  University: {result['university_name']}")
            print(f"   ğŸ”— Base URL: {result['base_url']}")
            print(f"   ğŸ‘¥ Faculty found: {result['metadata']['total_faculty']}")
            print(f"   ğŸ¢ Departments processed: {result['metadata']['departments_processed']}")
            print(f"   ğŸ“Š Discovery confidence: {result['metadata']['discovery_confidence']:.2f}")
            
            # Show some faculty examples
            if result["faculty"]:
                print(f"\nğŸ“‹ Sample Faculty (showing first 3):")
                for faculty in result["faculty"][:3]:
                    print(f"   ğŸ‘¤ {faculty.get('name', 'Unknown')}")
                    if faculty.get('title'):
                        print(f"      ğŸ“ Title: {faculty['title']}")
                    if faculty.get('email'):
                        print(f"      ğŸ“§ Email: {faculty['email']}")
                    if faculty.get('lab_url'):
                        print(f"      ğŸ”¬ Lab: {faculty['lab_url']}")
                    print()
            
            # Show department results
            if result["metadata"]["department_results"]:
                print("ğŸ¢ Department Results:")
                for dept_name, dept_data in result["metadata"]["department_results"].items():
                    print(f"   ğŸ“š {dept_name}:")
                    print(f"      ğŸ‘¥ Faculty: {dept_data['faculty_count']}")
                    print(f"      ğŸ—ï¸  Structure: {dept_data['structure_type']}")
                    print(f"      ğŸ“Š Confidence: {dept_data['confidence']:.2f}")
        else:
            print(f"âŒ Scraping failed: {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ Error during scraping: {e}")
        logger.error(f"Scraping failed: {e}")
    
    # Show crawler statistics
    stats = crawler.get_stats()
    print(f"\nğŸ“Š Crawler Statistics:")
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    await crawler.close()


async def demo_sitemap_analysis():
    """Demonstrate enhanced sitemap analysis capabilities."""
    
    print("\n" + "=" * 60)
    print("ğŸ—ºï¸  Enhanced Sitemap Analysis Demo")
    print("=" * 60)
    
    adapter = UniversityAdapter()
    
    # Test sitemap discovery on various universities
    test_cases = [
        ("Stanford University", "https://www.stanford.edu"),
        ("Carnegie Mellon University", "https://www.cmu.edu"),
    ]
    
    for name, base_url in test_cases:
        print(f"\nğŸ” Analyzing sitemaps for {name}")
        print(f"ğŸ”— Base URL: {base_url}")
        print("-" * 40)
        
        try:
            # Test enhanced sitemap discovery
            pattern = await adapter._discover_via_enhanced_sitemap(name, base_url)
            
            if pattern:
                print("âœ… Enhanced sitemap discovery successful!")
                print(f"   ğŸ“Š Confidence: {pattern.confidence_score:.2f}")
                print(f"   ğŸŒ Faculty patterns: {len(pattern.faculty_directory_patterns)}")
                
                if pattern.department_subdomains:
                    print(f"   ğŸ¢ Department subdomains discovered:")
                    for dept, url in pattern.department_subdomains.items():
                        print(f"      â€¢ {dept}: {url}")
                
                if pattern.subdomain_patterns:
                    print(f"   ğŸ”— Subdomain patterns: {len(pattern.subdomain_patterns)}")
            else:
                print("âŒ Enhanced sitemap discovery failed")
            
            # Test subdomain enumeration
            subdomain_pattern = await adapter._discover_via_subdomain_enumeration(name, base_url)
            
            if subdomain_pattern:
                print("âœ… Subdomain enumeration successful!")
                print(f"   ğŸ“Š Confidence: {subdomain_pattern.confidence_score:.2f}")
                if subdomain_pattern.department_subdomains:
                    print(f"   ğŸ¢ Enumerated subdomains:")
                    for dept, url in subdomain_pattern.department_subdomains.items():
                        print(f"      â€¢ {dept}: {url}")
            else:
                print("âŒ Subdomain enumeration found nothing")
                
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    await adapter.close()


async def main():
    """Run all demos."""
    try:
        await demo_enhanced_subdomain_discovery()
        await demo_enhanced_faculty_scraping()
        await demo_sitemap_analysis()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ Demo Complete!")
        print("=" * 60)
        print("\nâœ¨ Key Enhancements Demonstrated:")
        print("   ğŸ” Enhanced sitemap discovery with XML parsing")
        print("   ğŸŒ Multi-sitemap and sitemap index support")
        print("   ğŸ¢ Department-specific subdomain detection")
        print("   ğŸ”— Intelligent subdomain enumeration")
        print("   ğŸ›ï¸  University-specific pattern recognition")
        print("   ğŸ“Š Improved confidence scoring")
        print("   ğŸ›¡ï¸  Robust error handling and fallbacks")
        
    except Exception as e:
        logger.error(f"Demo failed: {e}")
        print(f"âŒ Demo failed: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 